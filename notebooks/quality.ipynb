{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4228.69s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spylls in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (0.1.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4235.10s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pagexml-tools in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (0.3.1)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.7.0 in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from pagexml-tools) (3.7.1)\n",
      "Requirement already satisfied: seaborn<0.13.0,>=0.12.2 in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from pagexml-tools) (0.12.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.22.3 in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from pagexml-tools) (1.23.5)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.5.3 in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from pagexml-tools) (1.5.3)\n",
      "Requirement already satisfied: xmltodict<0.13.0,>=0.12.0 in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from pagexml-tools) (0.12.0)\n",
      "Requirement already satisfied: py7zr<0.21.0,>=0.20.2 in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from pagexml-tools) (0.20.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /Users/carstenschnober/.local/lib/python3.10/site-packages (from pagexml-tools) (2.8.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.64.1 in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from pagexml-tools) (4.65.0)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.7.0 in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from pagexml-tools) (1.10.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.0->pagexml-tools) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.0->pagexml-tools) (4.39.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.0->pagexml-tools) (9.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.0->pagexml-tools) (1.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/carstenschnober/.local/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.0->pagexml-tools) (22.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.0->pagexml-tools) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.0->pagexml-tools) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from pandas<2.0.0,>=1.5.3->pagexml-tools) (2022.7.1)\n",
      "Requirement already satisfied: texttable in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from py7zr<0.21.0,>=0.20.2->pagexml-tools) (1.6.7)\n",
      "Requirement already satisfied: pycryptodomex>=3.6.6 in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from py7zr<0.21.0,>=0.20.2->pagexml-tools) (3.17)\n",
      "Requirement already satisfied: pybcj>=0.6.0 in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from py7zr<0.21.0,>=0.20.2->pagexml-tools) (1.0.1)\n",
      "Requirement already satisfied: psutil in /Users/carstenschnober/.local/lib/python3.10/site-packages (from py7zr<0.21.0,>=0.20.2->pagexml-tools) (5.9.4)\n",
      "Requirement already satisfied: pyzstd>=0.14.4 in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from py7zr<0.21.0,>=0.20.2->pagexml-tools) (0.15.4)\n",
      "Requirement already satisfied: brotli>=1.0.9 in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from py7zr<0.21.0,>=0.20.2->pagexml-tools) (1.0.9)\n",
      "Requirement already satisfied: inflate64>=0.3.1 in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from py7zr<0.21.0,>=0.20.2->pagexml-tools) (0.3.1)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from py7zr<0.21.0,>=0.20.2->pagexml-tools) (0.2.3)\n",
      "Requirement already satisfied: pyppmd<1.1.0,>=0.18.1 in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (from py7zr<0.21.0,>=0.20.2->pagexml-tools) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/carstenschnober/.local/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.8.2->pagexml-tools) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4241.40s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Users/carstenschnober/opt/anaconda3/envs/lahter/lib/python3.10/site-packages (4.65.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install spylls\n",
    "%pip install pagexml-tools\n",
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/carstenschnober/LAHTeR/workspace/nautilusocr')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "REPOSITORY_PATH = Path().parent.absolute()\n",
    "REPOSITORY_PATH"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE = \"nl\"\n",
    "\n",
    "HUNSPELL_DICT_PATH = REPOSITORY_PATH / 'dicts'\n",
    "assert HUNSPELL_DICT_PATH.is_dir()\n",
    "\n",
    "SUFFIXES = [\".aff\", \".dic\"]\n",
    "\n",
    "assert HUNSPELL_DICT_PATH.is_dir()\n",
    "\n",
    "assert all(\n",
    "    (HUNSPELL_DICT_PATH / Path(LANGUAGE).with_suffix(suffix)).is_file()\n",
    "    for suffix in [\".aff\", \".dic\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spylls.hunspell import Dictionary\n",
    "\n",
    "hunspell = Dictionary.from_files(str(HUNSPELL_DICT_PATH / Path(LANGUAGE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_score(tokens=[\"Dit\", \"is\", \"een\", \"text\"]):\n",
    "\n",
    "    matched_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    for token in tokens:\n",
    "        total_count += len(token)\n",
    "\n",
    "        # TODO: lowercase token?\n",
    "        matched_count += hunspell.lookup(token) * len(token)\n",
    "\n",
    "    return matched_count / total_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [\"Dit\", \"is\", \"een\", \"text\"]\n",
    "\n",
    "get_dict_score(tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Tri-Gram Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "HYPHENS = {\"-\", \"⸗\", \"=\"}\n",
    "\n",
    "\n",
    "def get_tokens(text) -> List[str]:\n",
    "    \"\"\"Copied from features_epr.py\"\"\"\n",
    "\n",
    "    tokens = list()\n",
    "\n",
    "    new_token = \"\"\n",
    "    for c in text:\n",
    "        if c == \" \" and len(new_token) > 0:\n",
    "            tokens.append(new_token)\n",
    "            new_token = \"\"\n",
    "        elif c == \"\\n\" and len(new_token) > 0:\n",
    "            if new_token[-1] in HYPHENS:\n",
    "                new_token = new_token[:-1]\n",
    "            else:\n",
    "                tokens.append(new_token)\n",
    "                new_token = \"\"\n",
    "        else:\n",
    "            new_token += c\n",
    "    if len(new_token) > 0:\n",
    "        tokens.append(new_token)\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        if not token[-1].isalpha():\n",
    "            tokens[i] = token[:-1]\n",
    "        if not token[0].isalpha():\n",
    "            tokens[i] = token[1:]\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "NGRAM_LENGTH = 3\n",
    "\n",
    "\n",
    "def get_ngrams(tokens) -> List[str]:\n",
    "    \"\"\"Copied, adapted from features_epr.py\"\"\"\n",
    "\n",
    "    n_grams = list()\n",
    "    for token in tokens:\n",
    "        token_list = list(token)\n",
    "        for i in range(0, len(token_list)):\n",
    "            if not token[i].isalpha():\n",
    "                token_list[i] = \" \"\n",
    "        modified_token = \"\".join(token_list)\n",
    "        splits = modified_token.split(\" \")\n",
    "        for split in splits:\n",
    "            if split != \"\":\n",
    "                for i in range(0, len(split) - NGRAM_LENGTH + 1):\n",
    "                    n_grams.append(split[i : i + NGRAM_LENGTH].lower())\n",
    "    return n_grams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_score(ngrams, lang_ngrams) -> float:\n",
    "    \"\"\"Copied from features_epr.py\"\"\"\n",
    "    # TODO: this is very slow\n",
    "    # TODO: check if this corresponds to equation 10 in the paper?\n",
    "\n",
    "    if len(ngrams) == 0:\n",
    "        return 0\n",
    "\n",
    "    score = 0\n",
    "    for ngram in ngrams:\n",
    "        for i in range(0, len(lang_ngrams)):\n",
    "            if ngram == lang_ngrams[i]:\n",
    "                score += 1 - (1 / len(lang_ngrams) * i)\n",
    "                break\n",
    "\n",
    "    score = score / len(ngrams)\n",
    "    return score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and decompress \"VOC Ground truths of the trainingset in PAGE xml.7z\" from https://zenodo.org/record/6414086\n",
    "\n",
    "GROUND_TRUTH_PATH = REPOSITORY_PATH / \"VOC Ground truths of the trainingset in PAGE xml\"\n",
    "assert (\n",
    "    GROUND_TRUTH_PATH.is_dir()\n",
    "), f\"Directory containing ground truth not found at {GROUND_TRUTH_PATH.absolute()}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading PageXML files: 100%|██████████| 20/20 [00:00<00:00, 42.30file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total n-grams: 9320\n",
      "Distinct n-grams: 1708\n",
      "Most common n-grams: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('nde', 151),\n",
       " ('den', 119),\n",
       " ('der', 113),\n",
       " ('oor', 112),\n",
       " ('van', 112),\n",
       " ('ten', 92),\n",
       " ('ver', 90),\n",
       " ('eer', 81),\n",
       " ('gen', 74),\n",
       " ('een', 71)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "from pagexml.parser import parse_pagexml_file\n",
    "from tqdm import tqdm\n",
    "\n",
    "N_FILES = 20\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "files = list(GROUND_TRUTH_PATH.glob(\"*.xml\"))\n",
    "\n",
    "pagexml_files = random.sample(files, N_FILES)\n",
    "\n",
    "lang_trigrams = list()\n",
    "\n",
    "for file in tqdm(pagexml_files, desc=\"Reading PageXML files\", unit=\"file\"):\n",
    "    pagexml = parse_pagexml_file(file)\n",
    "    for line in pagexml.get_lines():\n",
    "        tokens = get_tokens(line.text) if line.text else []\n",
    "        lang_trigrams.extend(get_ngrams(tokens))\n",
    "\n",
    "print(f\"Total n-grams: {len(lang_trigrams)}\")\n",
    "print(f\"Distinct n-grams: {len(set(lang_trigrams))}\")\n",
    "print(f\"Most common n-grams: \")\n",
    "\n",
    "Counter(lang_trigrams).most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23652762875536482"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Dit is eenasd teksthdgfhfgh\"\n",
    "\n",
    "tokens = get_tokens(text)\n",
    "trigrams = get_ngrams(tokens)\n",
    "\n",
    "get_ngram_score(trigrams, lang_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('teerd is voorgevallen', 0.9727282151104866),\n",
       " ('ren na dato den Resident hebben„', 0.9671975101337981),\n",
       " ('lijx vereerd soude sien wanneer', 0.9670892988474868),\n",
       " ('op soo als gesegt.', 0.9647313518504653),\n",
       " ('den tijd niets het geen eenige uijt', 0.9620598437772953),\n",
       " ('de laten weeten dat sig groote„', 0.9617285088199214),\n",
       " ('niets voorgevallen', 0.961472232940377),\n",
       " ('na de Jnlandse wijse onder een', 0.9612015595395096),\n",
       " ('ons afscheijd neemende weede„', 0.9601773029343503),\n",
       " ('Gaande den Resident met s EComp Donderdag „ 28.en', 0.9455443859875995),\n",
       " ('onderhoorige om onder een diver„', 0.943244124032783),\n",
       " ('makte sig des weegen heeden na„', 0.9401264678272988),\n",
       " ('trent 8 uuren in den avond', 0.9382421202365802),\n",
       " ('wierden onthaalt als wanneer', 0.9373009966133642),\n",
       " ('sijn komst maar ook diverse hee„', 0.931753280783752),\n",
       " ('Sondag „ 24„en', 0.9278748970577226),\n",
       " ('rom vertrocken terwijl in al', 0.9237745858244473),\n",
       " ('hem op sijn bodem quam besoeken', 0.920680969849945),\n",
       " ('derwaarts te vaaren alwaar aan„', 0.9149533016395897),\n",
       " ('niets vernomen,', 0.9136199911823181),\n",
       " ('breijding buijten ’t geseijde merit„', 0.910325244120258),\n",
       " ('balet van 5 maagden tot om„', 0.8988096129370368),\n",
       " ('de middag manescheijn gereet om', 0.8985902963416407),\n",
       " ('Pang: Mancooboemij niet alleen met Maandag „ 25„en', 0.8965118165256669),\n",
       " ('en boekhouder nicolaas martijn', 0.8735356584168364),\n",
       " ('van den opperchirurgijn g„t plancke', 0.8587893988170995),\n",
       " ('Van Jambij onder dato 20 Novemb„r 1738.', 0.8524797056653013),\n",
       " ('met sijn familie in geselschap', 0.8450648536347981),\n",
       " ('gekomen sijnde seer magnificq', 0.842450483724722),\n",
       " ('Dingsdag den 26„en', 0.8277789067262751),\n",
       " ('tissement', 0.8211959486197714),\n",
       " ('Saturdag den 23„en', 0.771724831281618),\n",
       " ('Woensdag „ 27„en', 0.7363055576351977),\n",
       " ('69', 0)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = random.choice(files)\n",
    "if file in pagexml_files:\n",
    "    raise ValueError(f\"Test file '{file}' must not be in sample of training files.\")\n",
    "\n",
    "parse_pagexml_file(file)\n",
    "\n",
    "\n",
    "scores = Counter()\n",
    "file_trigrams = list()\n",
    "\n",
    "for line in pagexml.get_lines():\n",
    "    text = line.text\n",
    "    tokens = get_tokens(text)\n",
    "    line_trigrams = get_ngrams(tokens)\n",
    "    scores[text] = get_ngram_score(line_trigrams, lang_trigrams)\n",
    "\n",
    "    file_trigrams.extend(line_trigrams)\n",
    "\n",
    "scores.most_common()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9127672833674267"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ngram_score(file_trigrams, lang_trigrams)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lahter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
